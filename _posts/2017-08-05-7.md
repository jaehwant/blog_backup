---
title: "Neural Network1, XOR 문제와 학습방법 (L08)"
description:
categories:
 - machinelearning
tags: 머신러닝
---

<!-- more -->

## 들어가며
모두를 위한 머신러닝/딥러닝 강의[^1] 를 수강하며 정리하는 페이지 입니다.      
* Lecture 8, XOR 문제 딥러닝으로 풀기 입니다.

## 강의정리
1. hunkim.github.io 강좌 Lecture 8번(XOR 문제 딥러닝으로 풀기) 입니다.

### Neural Network을 사용해서 XOR 풀기
기존에 Machine Learning이 정체되었던 시기에는 XOR 문제에 대해서 Machine Learning을 사용하여 풀 수 없다고 생각하던 시절이 있었습니다. 기존에 문제를 풀어나가던 방식으로는 풀 수 없다는 것이 수학적으로 증명되었습니다. 아마도 그 당시 Computing power 또한 낮았기 때문에 더 풀 수 없었던 것 습니다.

- XOR 이란?
Exclusive OR 연산으로 두개의 값이 같으면 0 다르면 1이 되는 논리연산 입니다.   
위의 그래프를 보면 알 수 있듯이 단순한 직선으로는 XOR를 구분할 수 없습니다.
![그림1. XOR by hunkim](/assets/images/DL_L8_xor.png)

- NN을 이용해서 XOR 풀기 (forward propagation)
기존에 사용하던 Logistic regression을 neural net으로 만들어서 푸는방법   
물론 이 방법도 예전에는 풀 수 없을 것이라는 확신에 가득한 이야기를 한 사람도 있습니다.   
> "No one on earth had found a viable way to train - Marvin Minsky"

![그림2. NN을 이용해 XOR 풀기 by hunkim](/assets/images/DL_L8_nn_1.png)

우선 각 Logistic Regression의 Weight 값과 Bias 값은 미리 정해놓고 NN으로 XOR을 풀 수 있는지 확인해보고 있습니다.

![그림3. NN을 이용해 XOR 풀기 by hunkim](/assets/images/DL_L8_nn_2.png)
위의 그림을 보고 값을 대입해서 풀어보면 NN으로 XOR을 푸는게 가능해 보입니다. 하지만 예제는 답이나올만한 Weight 값과 Bias를 입력했으니 쉽게 나오는 것 같지만, 예전에는 이 문제를 풀기가 어려웠습니다.
1. 간략한 설명 x1 = 0, x2 = 0 일때, (XOR 하면 답은 0이 나옴)
  1. 우선 첫번째 neurun에서 x1,x2를 사용하여 y1을 구합니다. 행렬곱을 해야 하는데요, 좀 풀어서 쓰면 아래처럼 됩니다.
  2. x1*w + x2*w -8, x1과 x2는 0이기 때문에 -8이 나옵니다. -8이라는 값을 sigmoid 함수를 수행하면 0보다 작기 때문에 0이 됩니다. 그래서 y1은 0이 됩니다.
  3. 이제 y2를 구해보겠습니다. 마찬가지로 x1*w + x2*w + 3이됩니다. x1,x2는 0이기 때문에 3이 나오고, 이 값을 sigmoid를 수행하면 0보다 크기 때문에 y2는 1이 됩니다.
  4. 자 이제 y1 = 0, y2 = 1이 나왔습니다. 이 값을 마지막 NN에 대입해서 풀어 봅니다. y1*w + y2*w + 6, 대입해보면 y1은 0이기 때문에 생략하면 -11 +6 이 됩니다. 그럼 -5가 됩니다. 이 값을 Sigmoid를 수행하면 값이 0보다 작기 때문에 0이 나옵니다.
  5. 즉 [0,0] 일때 출력은 0이 나왔습니다. (XOR과 동일하죠?)

![그림4. NN을 이용해 XOR 풀기 by hunkim](/assets/images/DL_L8_nn_3.png)
왼쪽의 Network을 matrix를 사용하여 오른쪽의 모양으로 수정할 수 있습니다. 즉 구현할때 두개의 Logistic regression 모양을 따로 생성하는게 아니라 matrix를 사용해서 한개로 묶어서 표현할 수 있습니다.


![그림5. 동일한 계층의 NN을 묶어서 matrix로 처리하는 방법 by hunkim](/assets/images/DL_L8_nn_4.png)
아까는 별개로 있던 network를 matrix를 이용해 하나로 합친 모습입니다.
실제로 구현하는 소스에서도 훨씬 간단하게 표현되는 것을 알 수 있습니다.
```python
K = tf.sigmoid(tf.matmul(X,W1) +b1)
hypothesis = tf.sigmoid(tf.matmul(K,W2) +b2)
```

### 여기까지는 이미 주어진 값으로 테스트해보는 방법이었습니다.
그럼 어떻게 W값과 b값을 자동으로 알아낼 수 있을까요?
W값과 b값을 안다는 것은 학습을 통해서 Cost를 계산하고 cost 가 minimize 된 값을 찾는 것을 뜻합니다.
이 부분이 어려워서 이 XOR 문제를 풀지 못했는데요. 풀 수 있게 해준 방법이 나왔습니다.

바로

Backpropagation 입니다.   
Backpropagation에 대해서는 다음시간에 조금더 자세히 포스팅하겠습니다.


## Reference
[^1]: [모두를 위한 머신러닝/딥러닝 강의](http://hunkim.github.io/ml/)


<!-- Tip

@목차 작성
## 대목차 (오른쪽에 1.대목차 로 보인다.)
### 소목차 (오른쪽에 1.1소목차 로 보인다.)
* 오른쪽 내어쓰기

@링크
[Text](링크주소)
![Text](그림주소)

@코드 삽입 (블럭)

```
노말 블럭 (highlight 없다 .)
```

```javascript
```python
```ruby

{% highlight ruby linenos %}
def foo
  puts 'foo'
end
{% endhighlight %}


@색상강조

`색강조(회색배경)`

@이모지 넣기
웃는 이모지 : :smile:

:bowtie::smile::laughing::blush::smiley::relaxed::smirk:
:heart_eyes::kissing_heart::kissing_closed_eyes::flushed::relieved::satisfied::grin:

@페이지 제목에 사진을 넣기(홈에서 미리보임)
photos:
- http://ww1.sinaimg.cn/mw690/81b78497jw1emfgwkasznj21hc0u0qb7.jpg
- http://ww3.sinaimg.cn/mw690/81b78497jw1emfgwjrh2pj21hc0u01g3.jpg
- http://ww2.sinaimg.cn/mw690/81b78497jw1emfgwil5xkj21hc0u0tpm.jpg
- http://ww3.sinaimg.cn/mw690/81b78497jw1emfgvcdn25j21hc0u0qpa.jpg

@테이블 넣기

| Table Header 1 | Table Header 2 | Table Header 3 |
| --- | --- | --- |
| Division 1 | Division 2 | Division 3 |
| Division 1 | Division 2 | Division 3 |
| Division 1 | Division 2 | Division 3 |

@테그 넣기
tags:
- Foo
- Bar
- Baz

@카테고리 넣기.
categories:
- Foo
- Bar
- Baz

-->
