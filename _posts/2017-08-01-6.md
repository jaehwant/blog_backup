---
title: "Machine learning system design (W6-2)"
description: 머신러닝 시스템 설계하는 방법 과 고려해야할 부분에 대해서 설명해주는 강의 입니다.
categories:
 - machinelearning
tags: 머신러닝
---

<!-- more -->

## 들어가며
Coursera의 Machine Learning[^1] by Andrew Ng교수님의 강의를 수강하며 정리하는 페이지 입니다.   
저도 배우고 있어서 일부 내용에 오류가 있을 수 있습니다.   
관련 부분에 대해서 추가되는 내용은 업데이트를 계속 해나갈 생각 입니다.

## 강의정리
Week6 의 2번째 챕터 입니다.([Machine Learning System Design](https://www.coursera.org/learn/machine-learning/home/week/6))   
머신러닝 시스템 설계하는 방법 과 고려해야할 부분에 대해서 설명해주는 강의 입니다.

### Prioritizing what to work on: Spam classification example
스팸필터를 어떻게 만들어야 할까요? 우선 아래의 스팸필터예제를 살펴보겠습니다.
스팸을 구분하는데 있어서 다양한 방법이 있겠지만, 단순히 아래처럼 일부단어에 의도적인 오타가 입려력되어 있고,
 특정한 단어를 많이 사용한다고 가정 합니다.
![그림1. Building a spam classifier by Andrew Ng](/assets/images/ML6_2_spam_filter_example_1.png)


우선 Supervised learning 방식으로 spam classifier를 만듭니다.   
학습데이터인 x는 spam에 사용된 단어로 우선 100개를 선정해서 feature를 만듭니다. y는 스팸인지 아닌지에 대한 결과값을 넣는데 사용 합니다.
![그림2. Building a spam classifier by Andrew Ng](/assets/images/ML6_2_spam_filter_example_2.png)

자 이제 아주 간단한 스팸 필터가 생성되었습니다.   
이제 이 스팸필터의 정확성을 높이기 위해서 어떤방법을 사용할 수 있을까요?
* 많은 양의 데이터를 수집한다. (허니팟[^2] : 스팸메일을 모아올 가상의 시스템)
* 스팸메일을 헤더를 이용한다. 그리고 유사단어와 다른단어를 구분할 알고리즘을 개발한다.
* 잘못된 철자(w4tch)를 처리하는 알고리즘 을 개발한다.

하지만 위의 방법중 어떤 것이 가장 좋을지는 선택하기엔 어렵습니다.

### Error analysis
제안 하는 접근 방법   
1. 신속하게 구현해본다. 간단한 알고리즘으로 시작하고 교차검증[^3] 데이터를 사용해 테스트해본다
2. 학습곡선을 그려본다. 학습곡선을 통해 데이터가 더 필요한지, feature 가 필요한지 결정할 수 있다.
3. 교차검증데이터를 활용해서 어떤 부분에 오류가 발생했는지 분석해본다.

![그림3. Error Analysis by Andrew Ng](/assets/images/ML6_2_spam_filter_example_3.png)
약 500개의 교차검증 셋이 있고, 이 중에서 약 100개가 잘못 분류되었다고 한다면 직접 100개가 잘못 분류된 원인을 분석해볼 수 있습니다.
예를들면 잘못분류된 스팸메일의 종류를 분류해볼 수 있습니다.(약물판매,유사제품,피싱메일,그외)
또는 의도되 오타(med1cine)를 검출하거나, 이상한 문장부호를 사용하는 것을 찾을 수 있습니다.   
위에서도 이야기했지만, 신속하고 간단한 알고리즘으로 시작하는것은 이런 교차검증 셋으로 미쳐 발견하지 못했던 문제점들을 분석하고 찾을 수 있기 때문입니다.

### The importance of numerical evaluation
알고리즘을 평가할때 숫자로 평가할 수 있어야 합니다. 아래의 예를 살펴 보겠습니다.   
유사단어에 대해서 stemming software를 사용할 수 있습니다.   
예를들면 discount, discounts, discounted, discounting 을 discount 한단어로 처리할 수 있습니다.
이런 소프트웨어를 "stemming software[^4][^5]" 라고 합니다. 이렇게 유사단어들에 대해서 stemming software 를 적용한다면, 더 적은 수의 feature를 사용할 수 있습니다.
하지만 stemming software 에도 문제점은 있습니다. 예를들면 univers 와 university를 구분하는것은 잘못 구분될 수 있습니다.

그럼 이러한 stemming software를 사용해야 할까요? 거기에 대한 판단을 바로 적용했을 때의 결과 에러율을 보고 판단할 수 있습니다.
* Stemmer를 사용하지 않았을 때 : 5% 에러
* Stemmer를 사용했을 때 : 3% 에러

위처럼 적용했을 때의 통계가 사용했을 때 에러율이 더 낮아진다면 사용하는게 좋을 수 있습니다.

그리고 강좌에서 Andrew Ng은 머신러닝 시스템을 디자인 할 때, 빠르게 알고리즘을 설계하고 구현하는것이 좋다고 합니다. 초기에 많은 시간을 들이는 것 보다
빠르게 구현해보고 모델에 대해 평가해본 후, 부족한 점에 대해서 보완하는 것이 빠르고 시간이 절약된다고 합니다.

### Error metirics for skewed classes
예전에 예로 다루었던 cancer classification을 다시 보겠습니다.
![그림4. Cancer classification example by Andrew Ng](/assets/images/ML6_2_spam_filter_example_4.png)
logistic regression 모델을 사용해서 1%의 오류율을 달성했다고 합시다.   
과연 이 시스템은 잘 만들어진걸까요? 맞을 확률이 99%나 되니까 잘 된걸까요?

여기서 입력데이터의 skewed classes의 문제가 발생합니다.
* skewed classes : Train 데이터가 한쪽으로 치우쳐져 있는 경우 (예를들면 전체 데이터에서 대부분 암이 아닐때,)

내가만든 logistic regression 모델의 에러율은 1%이지만, 실제로 전체 환자의 99.5%가 암이 아닙니다.    
즉 모든 training set에 대해서 y= 0(cancel 이 아님)을 나타내도 에러율이 0.5%가 된다는 것입니다.
이렇게 skewed 된 class에서는 위와 같은 문제가 발생하게 됩니다. 단순히 에러율만을 가지고는 모델을 평가하기 어렵습니다.

그럼 어떻게 해야할까요?

에러율 이외에 시스템을 평가할 수 있는방법은  Precision(정밀도) 과 Recall(재현율) matrix 가 있습니다.

* 링크 : [precision 과 recall의 이해](http://darkpgmr.tistory.com/162)
* Precision(정밀도) :  검출된 결과가 얼마나 정확한지 여부
* Recall(재현율) : 실제 검출되어야할 결과가 얼마나 잘 나왔는지 여부


| | Actual class 1(True) | Actual class 0 (False) |
|:----:|:----:|:----:|
| predicted class 1(True) | True positive | False positive |
| Predicted class 0(False) | False negative | True negative |

실제 암환자가 100명중에 5명(5%) 있다고 가정해 봅시다. 제가 만든 linear regression 모델로는 10%의 확률로 검출합니다.   
즉 100명의 환자에서 10명이 암이 있다고 예측 했습니다.   

자 이제 이 결과가 맞다고 할 수 있을까요?   
분류하는 것도 중요하지만, 얼마나 정확하게 실제의 데이터를 분류해냈는지도 검토해봐야 합니다.
위의 예를 가지고 다시 Metrics 를 그려 보겠습니다.

| | Actual class 1(True) | Actual class 0 (False) |
|:----:|:----:|:----:|
| predicted class 1(True) | 3 | 7 |
| Predicted class 0(False) | 2 | 88 |

실제 암환자의 수는 5명 입니다.   
우리의 시스템은 암을 10명 있다고 분류하였습니다.(실제로 10명중에서 3명이 암 입니다.)   
그리고 암이 아니라고 분류된 것은 90명 입니다. (실제로 90명 중에서 2명은 암 입니다.)

여기서 Precision(정확도) = (True Positive)/(True positive + False Positive) 입니다.
* Precision(정확도) = (3) / (3+ 7) = 30%
즉 모델에서 예측한 10명중에 실제 암은 3명으로 검출의 정확도가 30%밖에 안되는 것이죠.

여기서 Recall(재현율) = (True Positive) / (True Positive + (False Negative)
* Recall(재현율) = (3) / (3 + 2) = 60%
즉 모델의 결과가 실제 암을 얼마나 찾아 냈는지 여부를 나타 냅니다.

### Trading off precision and recall
Precision 과 Recall을 모두 만족시킬 수는 없을까요?
![그림5. trading off precision and recall by Andrew Ng](/assets/images/ML6_2_spam_filter_example_5.png)
안타깝게도 precision 과 recall은 Trade off 관계 입니다.   
암을 진단하는 Tumer의 사이즈의 임계값을 증가시킨다고 가정해 봅시다. 그렇게되면 암이라고 판단되는 경우는 줄어 들게 됩니다.
(암을 구별하는 임계값이 높아졌기 때문에) 이렇게되면 Precision은 증가합니다. 하지만 암을 암으로 판단하지 못하는 경우가 발생하기 때문에
Recall은 낮아지게 됩니다.   
정확도는 증가하지만, 재현율은 감소되는 것이죠.

반대로 암을 판단하는 임계값을 낮춘다고 가정해 봅시다.   
임계값이 낮아졌기 때문에 암으로 판단되는 수는 많아 집니다. 당연히 정확도는 감소하게 됩니다.
반대로 실제 암을 암이라고 판단할 확률이 높아지기 때문에 잘못 구분할 확률이 줄어들어서 재현율은 높아집니다.   
정확도는 낮아졌지만, 재현율은 높아지는 것이죠.

그 둘의 상관관계가 위 그림의 오른쪽에 있는 그래프 입니다.   
Threshold가 0.09이면 실제 암보다 암을 적게 분류하기 때문에(반대로 Error가 감소) 정확도는 높아집니다. 하지만 실제 암을 정확히 분류하지
못했기 때문에 재현율은 감소 되죠.   
Threshold가 0.01이면 실제 암보다 암을 많이 분류하기 때문에(Error가 증가) 정확도가 낮아집니다. 하지만 실제 암은 더 많이 포함되기 때문에
재현율은 증가하게 됩니다.

**그럼 최적의 Threshold는 어떻게 결정해야 할까요?**
Precision 과 recall 을 조합해서 사용하면 됩니다. 바로 **F score** 입니다.
* F score = 2 * (Precision * Recall) / (Precision + Recall)

![그림6. F Score  by Andrew Ng](/assets/images/ML6_2_spam_filter_example_6.png)

위의 3개의 알고리즘 중에서 F score 가 높은 Algorithm 1 이 가장 좋다는 것을 알 수 있습니다.

### Data for machine learning

![그림7. Desiging a high accuracy learning system](/assets/images/ML6_2_spam_filter_example_7.png)
단어나 문장을 완성하는 머신러닝 알고리즘을 만들 때 위와 같은 알고리즘들을 사용할 수 있습니다.
(perceptron, Winnow, Memory-based, naive Bayes 등등)

그림7의 오른쪽의 그래프를 보면 Training set의 크기에 따라서 점차 정확도가 비슷해진다는 것을 확인할 수 있습니다.
즉 좋은 알고리즘을 사용하는 것도 중요하지만, Training set를 많이 보유하는 것도 중요하다는 것을 알 수 있습니다.

![그림8. large data rationale](/assets/images/ML6_2_spam_filter_example_8.png)
많은 데이터를 가지고 있는 것도 중요하지만, 그 중에서 좋은 정보가 무었인지 구분하는 것도 중요합니다.   
집을 구하는 것을 예를 들면 집의 평수만을 가지고 집값을 대략적으로 예측할 수 는 있습니다. 하지만 크기만이 집값을 결정하는
요소는 아닌데요, 다양한 요소들이 있을 수 있습니다. 방의 갯수, 위치, 주변시설등이 있습니다. 이 Feature에 대한 영향력을 어떻게 검증할 수 있을까요?
그리고 이 Feature가 영향을 줄 수 있는지 어떻게 알 수 있을까요? 좀더 쉬운 방법중 하나는 사람(전문가)가 주어진 x와 y로 예측할 수 있는지 검토해보는 것 입니다.

![그림9. large data rationale](/assets/images/ML6_2_spam_filter_example_9.png)
많은 데이터를 사용해서 알고리즘을 구현할 때 많은 Feature를 사용하는 logistic regression/linear regression 과 많은 수의 hidden unit을 사용하는
neural network들은 **low bias algorithm** 일 가능성이 높습니다.

또한 많은 training set 을 사용하게 되면 overfit 되어 Jtest 와 Jtrain이 비슷해질 수 있습니다.

이전 강의에서 다룬 bias와 variance에 대해 배운것처럼 알고리즘이 어떤 성향을 보이는지 여부에 따라 알고리즘의 복잡도를 조절하거나, 데이터의 양을 늘림으로서
좋은 결과를 나타내는 머신러닝 시스템을 만들 수 있습니다.

* [링크 : Bias-Variance Tradeoff:경험에서 배울 때 주의사항](http://www.4four.us/article/2010/11/bias-variance-tradeoff)


## Reference
[^1]: [Coursera : Machine Learning Stanford University](https://www.coursera.org/learn/machine-learning/home/welcome)
[^2]: [허니팟(honeypot) 해커들을 유인하는 꿀단지, 즉 정보가 있는 것처럼 보이는 가상 시스템 :](https://en.wikipedia.org/wiki/Honeypot_(computing))
[^3]: 교차검증(corss-validation data) : 예를들면 Supervised learning 을 위한 학습데이터가 있다면 (60%는 traing set, 20% 는 cross validation set, 20%는 test set으로 사용)
[^4]: [stemming software](https://ko.wikipedia.org/wiki/%EC%96%B4%EA%B0%84_%EC%B6%94%EC%B6%9C)
[^5]: [Poter stemmer](https://tartarus.org/martin/PorterStemmer/)


<!-- Tip

@목차 작성
## 대목차 (오른쪽에 1.대목차 로 보인다.)
### 소목차 (오른쪽에 1.1소목차 로 보인다.)
* 오른쪽 내어쓰기

@링크
[Text](링크주소)
![Text](그림주소)

@코드 삽입 (블럭)

```
노말 블럭 (highlight 없다 .)
```

```javascript
```python
```ruby

{% highlight ruby linenos %}
def foo
  puts 'foo'
end
{% endhighlight %}


@색상강조

`색강조(회색배경)`

@이모지 넣기
웃는 이모지 : :smile:

:bowtie::smile::laughing::blush::smiley::relaxed::smirk:
:heart_eyes::kissing_heart::kissing_closed_eyes::flushed::relieved::satisfied::grin:

@페이지 제목에 사진을 넣기(홈에서 미리보임)
photos:
- http://ww1.sinaimg.cn/mw690/81b78497jw1emfgwkasznj21hc0u0qb7.jpg
- http://ww3.sinaimg.cn/mw690/81b78497jw1emfgwjrh2pj21hc0u01g3.jpg
- http://ww2.sinaimg.cn/mw690/81b78497jw1emfgwil5xkj21hc0u0tpm.jpg
- http://ww3.sinaimg.cn/mw690/81b78497jw1emfgvcdn25j21hc0u0qpa.jpg

@테이블 넣기

| Table Header 1 | Table Header 2 | Table Header 3 |
| --- | --- | --- |
| Division 1 | Division 2 | Division 3 |
| Division 1 | Division 2 | Division 3 |
| Division 1 | Division 2 | Division 3 |

@테그 넣기
tags:
- Foo
- Bar
- Baz

@카테고리 넣기.
categories:
- Foo
- Bar
- Baz

-->
